# Agents_Evaluation
This repository is dedicated to exploring, implementing, and evaluating various agentic workflows using cutting-edge tools and frameworks. The primary focus is on creating intelligent, interactive systems where agents collaborate to perform complex tasks in a structured and efficient manner. By leveraging tools like AgentNeo and integrating frameworks such as Promptflow (to be added), this repository aims to serve as a comprehensive resource for understanding and refining agentic workflows.

Current Features
1. AgentNeo Integration
What is AgentNeo?
AgentNeo is a versatile framework designed for managing agent-based systems. It allows users to configure, monitor, and evaluate interactions among multiple agents.
Capabilities Implemented:
Multi-agent collaboration: Agents can perform tasks collaboratively using predefined roles and workflows.
Tracing and debugging: Track the internal workflows of agents with detailed visual dashboards.
Customizable configurations: Load and manage model configurations dynamically using JSON files or environment variables.
2. Interactive Multi-Agent Workflows
Use Cases:

Building creative systems (e.g., collaborative storytelling).
Refining outputs by introducing agents with specialized roles (e.g., tone correction, suggestion generation).
Testing conversational flows for real-world scenarios.
Features Implemented:

Round-robin message handling among agents to ensure balanced participation.
Support for OpenAI's GPT models with flexible configurations.
Visualization of agent interactions using the AgentNeo dashboard.
Planned Enhancements
1. Integration with Promptflow
What is Promptflow?
Promptflow is a tool designed to refine and experiment with prompts for large language models. It supports evaluating prompt effectiveness and improving interaction quality.
Planned Features:
Seamless integration with existing AgentNeo workflows.
Dynamic prompt evaluation and refinement for better agent responses.
Support for visualizing prompt effectiveness and interaction flows.
2. Enhanced Workflow Evaluation
Comparative analysis of agent responses across models.
Metrics to evaluate the quality of task execution and collaboration among agents.
Support for custom evaluation pipelines based on user-defined criteria.
